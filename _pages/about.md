---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
  - /chinese-version
---


# About
* [Xu Tan](https://scholar.google.com/citations?user=tob-U1oAAAAJ) is a Reasearch VP of Multimodality at Moonshot AI (a.k.a [Kimi](https://kimi.moonshot.cn/)). He is previously a Principal Research Manager at Machine Learning Group, Microsoft Research Asia ([MSRA](https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/)). His work area covers LLMs, multimodality, and generative AI for video and audio. 
* His has published influential research papers with [15000+ citations](https://scholar.google.com/citations?user=tob-U1oAAAAJ), with two best papers and several top cited papers at AI conferences.
* He designed several models/systems on video (e.g., [Kimi-Video](https://mp.weixin.qq.com/s/BfAf094vFHPkN_CQFDvYdg), [LanDiff](https://arxiv.org/pdf/2503.04606), [GAIA](https://arxiv.org/pdf/2311.15230)), audio (e.g., [Kimi-Audio](https://arxiv.org/pdf/2504.18425), [FastSpeech 1/2](https://www.microsoft.com/en-us/research/blog/fastspeech-new-text-to-speech-model-improves-on-speed-accuracy-and-controllability/), [NaturalSpeech 1/2/3](https://techcommunity.microsoft.com/t5/ai-cognitive-services-blog/new-technical-research-is-advancing-azure-s-neural-text-to/ba-p/3499414), [Muzic](https://github.com/microsoft/muzic)), language (e.g., [MASS](https://www.microsoft.com/en-us/research/blog/introducing-mass-a-pre-training-method-that-outperforms-bert-and-gpt-in-sequence-to-sequence-language-generation-tasks/), [MPNet](https://www.microsoft.com/en-us/research/blog/mpnet-combines-strengths-of-masked-and-permuted-language-modeling-for-language-understanding/)), and AI agent (e.g., [HuggingGPT](https://arxiv.org/abs/2303.17580)).
* He has many technologies deployed in products: 1) Kimi-Video/Kimi-TTS in Kimi; 2) neural machine translation, pre-training models ([MASS](https://arxiv.org/abs/1905.02450), [MPNet](https://arxiv.org/abs/2004.09297)), TTS ([FastSpeech 1](https://www.microsoft.com/en-us/research/blog/fastspeech-new-text-to-speech-model-improves-on-speed-accuracy-and-controllability/)/[2](https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/articles/fastspeech-2-fast-and-high-quality-end-to-end-text-to-speech/)), ASR ([FastCorrect 1](https://arxiv.org/abs/2105.03842)/[2](https://arxiv.org/abs/2109.14420)), AI Music (https://github.com/microsoft/muzic), and AI avatar deployed in Microsoft (e.g., Bing Search/Ads, Microsoft Translator, Azure TTS, Azure ASR, Microsoft Xiaoice, etc).
* He and the team have several opensource projects on Github (with 30K+ stars), such as [HuggingGPT/JARVIS](https://github.com/microsoft/JARVIS), [Kimi-Audio](https://github.com/MoonshotAI/Kimi-Audio), [MASS](https://github.com/microsoft/mass), [MPNet](https://huggingface.co/transformers/model_doc/mpnet.html), and [Muzic](https://github.com/microsoft/muzic).
* He is an Action Editor of [Transactions on Machine Learning Research (TMLR)](https://www.jmlr.org/tmlr/), an Area Chair or Meta Reviewer of NeurIPS/ICML/AAAI/ICASSP, a senior member of IEEE, and a member of the standing committee on [Computational Art](https://www.ccf.org.cn/Chapters/CCF_Chapters/CCF_CA/) in China Computer Federation (CCF).



<!--
## We are hiring! 
* We are hiring researchers on *Multimodality, Machine Translation/NLP, Speech, Generative Models, and Deep Learning*! If you are interested, welcome to contact me: [tanxu2012@gmail.com](tanxu2012@gmail.com).
* We are also hiring research interns in the above directions.

 

## Featured Projects
### 1. Neural Machine Translation
* Multiple technologies transferred into Microsoft Translator to improve the product experience.
* We [achieved human parity](https://blogs.microsoft.com/ai/chinese-to-english-translator-milestone/) on Chinese-English machine translation in 2018.
* We won [several champions](https://news.microsoft.com/apac/2019/05/22/microsoft-research-asia-msra-leads-in-2019-wmt-international-machine-translation-competition/) on WMT machine translation competition in 2019. 
* Our [MASS](https://arxiv.org/abs/1905.02450) is the first pre-training model for sequence to sequence generation, and is one of the top cited papers in ICML 2019. MASS is deployed in [Microsoft Translator](https://www.bing.com/translator) to enable the translation of 10+ low-resource languages. [[blog]](https://www.microsoft.com/en-us/research/blog/introducing-mass-a-pre-training-method-that-outperforms-bert-and-gpt-in-sequence-to-sequence-language-generation-tasks/) [[code]](https://github.com/microsoft/MASS)

### 2. Text to Speech
* Multiple technologies (FastSpeech 1/2, LRSpeech, AdaSpeech 1/2/3, DelightfulTTS) deployed in Microsoft Azure TTS services.  
* Our [FastSpeech 1](https://www.microsoft.com/en-us/research/blog/fastspeech-new-text-to-speech-model-improves-on-speed-accuracy-and-controllability/)/[2](https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/articles/fastspeech-2-fast-and-high-quality-end-to-end-text-to-speech/) are one of the most widely used technologies in TTS in both academia and industry, and are the backbones of many TTS and singing voice synthesis models. Support over 100+ languages in Azure TTS services. Integrated in some popular Github repos, such as ESPNet, Fairseq, NVIDIA Nemo, TensorFlowTTS, Baidu PaddlePaddle Parakeet, etc.
* [DelightfulTTS](https://arxiv.org/abs/2110.12612) achieved the best quality in Blizzard Speech Synthesis Challenge 2021.
* [NaturaSpeech](https://arxiv.org/abs/2205.04421) achieves human-level quality on text-to-speech synthesis on LJSpeech dataset for the first time. 
* [NaturalSpeech 2](https://arxiv.org/abs/2304.09116) achieves SOTA zero-shot synthesis quality with latent diffusion models.
* The most comprehensive [TTS Survey](https://arxiv.org/abs/2106.15561).
* [TTS Tutorials](https://github.com/tts-tutorial/) at ISCSLP 2021, IJCAI 2021, ICASSP 2022, INTERSPEECH 2022. 
* Speech project demo page: [https://speechresearch.github.io/](https://speechresearch.github.io/), code opensource page: [https://github.com/microsoft/NeuralSpeech](https://github.com/microsoft/NeuralSpeech).

### 3. AI Music Composition
* Multiple technologies (TeleMelody, XiaoiceSing, and HiFiSinger) integrated in Microsoft Azure and Microsoft Xiaoice for AI music composition. 
* Systematic research on songwriting, accompaniment and arrangement, singing voice synthesis, music understanding, etc. Keynote speaker on [AI music composition](https://mp.weixin.qq.com/s/0ef2Xn7oSGYlip7LEzHXog) at GAITC 2021. Tutorial on [AI music composition](https://www.microsoft.com/en-us/research/uploads/prod/2021/10/Tutorial-on-AI-Music-Composition-@ACM-MM-2021.pdf) at ACM MM 2021.   
* Muzic: our research project on AI music, https://github.com/microsoft/muzic. 

### 4. Other Projects
### 4.1. Pre-training
* Several research work on pre-training (MASS, MPNet, Transcormer, NAS-BERT, MP-BERT, SongMASS, MusicBERT, etc).
* [MASS](https://arxiv.org/pdf/1905.02450.pdf) deployed in Bing Ads for Ads content generation, and deployed in Bing Translation for low-resource languages. 
* [MPNet](https://arxiv.org/pdf/2004.09297.pdf) adopted in [Huggingface](https://huggingface.co/transformers/model_doc/mpnet.html).

### 4.2. Non-Autoregressive Sequence Generation
* Several papers (FastSpeech 1/2, AdaSpeech 1/2/3, NaturalSpeech, HiFiSinger, FastCorrect 1/2/3, etc) on non-autoregressive sequence generation on text and speech generation tasks, such as neural machine translation, text error correction, automatic speech recognition, text to speech, singing voice synthesis, etc.
* Give a [tutorial on non-autoregressive sequence generation](https://nar-tutorial.github.io/acl2022/) at ACL 2022. 

### 4.3. Efficient Machine Learning
* Design efficient models and algorithms to reduce the demands on big data, big model and big computation, with small latency/memory/computation/labeling cost. 

### 4.4. Multilingual and Low-Resource Scenarios
### 4.5. Model Structure and Learning Paradigm Design
### 4.6. Neural Architecture Search 


<br/>
<br/>
For Chinese version, please visit [https://tan-xu.github.io/chinese-version/](https://tan-xu.github.io/chinese-version/). <br/>
--> 



